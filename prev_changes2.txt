elastic -

import copy
import json
import logging
import os
import warnings
from typing import Dict

import boto3
from requests import Session, Response
from requests_aws4auth import AWS4Auth
from requests.exceptions import HTTPError

from common.search_query_template import OrderField
from common.std_ext import NullObject
from common.errors import AccessDeniedError, ElasticsearchFailedRequestError  # Ensure these are imported

# Set log level to INFO
log_level = os.environ.get("LOG_LEVEL", "INFO")
logging.root.setLevel(logging.getLevelName(log_level))
_logger = logging.getLogger(__name__)

AWS_REGION = "ca-central-1"
ES_HEADERS = {"Content-Type": "application/json"}

def append_order_by(query_dict: dict, order_field: OrderField) -> dict:
    query_sort = {
        order_field.field: {
            "order": order_field.direction,
            "missing": order_field.missing,
        }
    }
    query_dict["sort"] = [query_sort]
    return query_dict

def offset_paginator_factory(limit=10, strategy="offset"):
    def append_pagination_with_from_size(query_dict, offset=0):
        query_dict["size"] = limit
        query_dict["from"] = offset
        return query_dict

    if strategy == "offset":
        return append_pagination_with_from_size

class ElasticSearchV2:
    def __init__(
        self, host: str, auth: AWS4Auth | Dict, use_ssl: bool = True, logger=None
    ):
        if logger is None:
            logger = NullObject()

        if not auth:
            raise ValueError("Elasticsearch credentials are required and must be provided.")
        
        protocol = "https" if use_ssl else "http"
        self.es_url = f"{protocol}://{host}"
        self.logger = logger
        self.auth = auth
        self.session = self.__create_session(self.auth)

    def __create_session(self, auth: AWS4Auth | Dict) -> Session:
        session = Session()
        session.headers = ES_HEADERS
        session.auth = auth
        return session

    def __request(self, verb: str, endpoint: str, body: Dict = None) -> Response:
        if body is not None:
            body = json.dumps(body)

        self.logger.info("Elasticsearch request: %s %s/%s", verb, self.es_url, endpoint)
        self.logger.info("Elasticsearch body: %s", body)

        try:
            response = self.session.request(
                method=verb, url=f"{self.es_url}/{endpoint}", data=body
            )
            response.raise_for_status()
        except HTTPError as http_err:
            self.logger.error(f"HTTP error occurred: {http_err}")
            if response.status_code == 403:
                raise AccessDeniedError("403 Forbidden: Access to Elasticsearch denied.")
            else:
                raise ElasticsearchFailedRequestError(
                    f"HTTP error {response.status_code} from Elasticsearch: {response.text}"
                )
        except Exception as e:
            self.logger.error(f"Elasticsearch error: {e}")
            raise ElasticsearchFailedRequestError(f"Error with Elasticsearch server: {str(e)}")

        return response

    def request(self, verb: str, endpoint: str, body: Dict) -> Dict:
        warnings.warn(
            "Deprecated function, use specific Elasticsearch function instead.",
            DeprecationWarning,
        )
        response = self.__request(verb, endpoint, body)
        return json.loads(response.text)

    def get_document(self, index: str, _id: str) -> Dict:
        endpoint = f"{index}/_doc/{_id}"
        response = self.__request(verb="GET", endpoint=endpoint)
        return json.loads(response.text)

    def search_documents(self, index: str, query: Dict) -> Dict:
        """Search for documents in Elasticsearch with error handling."""
        try:
            endpoint = f"{index}/_search"
            response = self.__request(verb="GET", endpoint=endpoint, body=query)
            return json.loads(response.text)
        except AccessDeniedError as e:
            self.logger.error("AccessDeniedError while searching documents: %s", e)
            raise
        except ElasticsearchFailedRequestError as e:
            self.logger.error("Failed request to Elasticsearch during search: %s", e)
            raise
        except Exception as e:
            self.logger.error(f"Unexpected error in search_documents: {e}")
            raise ElasticsearchFailedRequestError("Unexpected error occurred during search.")

    def add_document(self, index: str, _id: str, document: Dict) -> Dict:
        """Create a full document."""
        try:
            endpoint = f"{index}/_doc/{_id}"
            response = self.__request(
                verb="PUT",
                endpoint=endpoint,
                body=document,
            )
            return json.loads(response.text)
        except Exception as e:
            self.logger.error(f"Error while adding document to Elasticsearch: {e}")
            raise ElasticsearchFailedRequestError(f"Error adding document to Elasticsearch: {str(e)}")

    def update_document(
        self, index: str, _id: str, document: Dict, max_retries: int = 3
    ) -> Dict:
        """Overwrite or create a full document."""
        try:
            endpoint = f"{index}/_update/{_id}?retry_on_conflict={max_retries}"
            response = self.__request(verb="POST", endpoint=endpoint, body=document)
            return json.loads(response.text)
        except Exception as e:
            self.logger.error(f"Error while updating document in Elasticsearch: {e}")
            raise ElasticsearchFailedRequestError(f"Error updating document in Elasticsearch: {str(e)}")

    def update_partial_document(
        self, index: str, _id: str, partial_document: Dict, max_retries: int = 3
    ) -> Dict:
        """Update a partial section of a document."""
        try:
            endpoint = f"{index}/_update/{_id}?retry_on_conflict={max_retries}"
            updated_document = {"doc": partial_document}
            response = self.__request(verb="POST", endpoint=endpoint, body=updated_document)
            return json.loads(response.text)
        except Exception as e:
            self.logger.error(f"Error while partially updating document in Elasticsearch: {e}")
            raise ElasticsearchFailedRequestError(f"Error partially updating document in Elasticsearch: {str(e)}")

    def update_partial_document_by_query(
        self, index: str, _id: str, update_query: Dict, max_retries: int = 3
    ) -> Dict:
        """Update a partial section of a document using a script."""
        try:
            endpoint = f"{index}/_update/{_id}?retry_on_conflict={max_retries}"
            response = self.__request(verb="POST", endpoint=endpoint, body=update_query)
            return json.loads(response.text)
        except Exception as e:
            self.logger.error(f"Error while updating document by query in Elasticsearch: {e}")
            raise ElasticsearchFailedRequestError(f"Error updating document by query in Elasticsearch: {str(e)}")

    def update_documents_by_query(
        self, index: str, update_query: Dict, max_retries: int = 3
    ) -> Dict:
        """Update multiple documents by an update query."""
        try:
            endpoint = f"{index}/_update_by_query/?retry_on_conflict={max_retries}"
            response = self.__request(verb="POST", endpoint=endpoint, body=update_query)
            return json.loads(response.text)
        except Exception as e:
            self.logger.error(f"Error while updating multiple documents in Elasticsearch: {e}")
            raise ElasticsearchFailedRequestError(f"Error updating multiple documents in Elasticsearch: {str(e)}")

def create_es_client(host: str, auth: AWS4Auth | Dict, use_ssl: bool = True, logger=None) -> ElasticSearchV2:
    """Creates an Elasticsearch client."""
    if not auth:
        raise ValueError("Elasticsearch credentials are required and must be provided.")

    es_client = ElasticSearchV2(host=host, auth=auth, use_ssl=use_ssl, logger=logger)
    return es_client
-------------------
from common.elasticsearch import ElasticSearchV2, create_es_client
from common.errors import (
    AccessDeniedError,
    ValidationError,
    ConfigurationError,
    SQSError,
    ElasticsearchFailedRequestError,  # Add this import if not already present
)
from requests_aws4auth import AWS4Auth  # Ensure this is imported

def build_handler(create_dynamodb_client_fn, create_es_client_fn, create_sqs_client_fn):
    validate_env_variables(
        "ELASTICSEARCH_INDEX",
        "ELASTICSEARCH_HOST",
        "TRANSCRIBE_ON_REQUEST_STATUS_TABLE",
        "DAYS_TO_EXPIRE",
        "AUDIO_SOURCE_BUCKET",
        "AUDIO_SOURCE_PREFIX",
        "SQS_QUEUE_URL",
    )
    transcribe_on_request_status_table = os.environ[
        "TRANSCRIBE_ON_REQUEST_STATUS_TABLE"
    ]

    days_to_expire = int(os.environ["DAYS_TO_EXPIRE"])
    host = os.environ["ELASTICSEARCH_HOST"]
    es_index = os.environ["ELASTICSEARCH_INDEX"]
    
    try:
        # Ensure the credentials are provided and create the Elasticsearch client
        credentials = boto3.Session().get_credentials()
        auth = AWS4Auth(
            credentials.access_key,
            credentials.secret_key,
            AWS_REGION,
            "es",
            session_token=credentials.token,
        )
        
        es_client = create_es_client_fn(host=host, auth=auth, use_ssl=True)
    except ValueError as e:
        logger.error(f"Failed to create Elasticsearch client: {e}")
        # Raise a configuration error if credentials are missing or invalid
        raise ConfigurationError(f"Elasticsearch client configuration failed: {str(e)}")
    except AccessDeniedError as e:
        logger.error(f"Access denied when creating Elasticsearch client: {e}")
        raise AccessDeniedError("403 Forbidden: Access to Elasticsearch denied.")
    except Exception as e:
        logger.error(f"Unexpected error during Elasticsearch client creation: {e}")
        raise ConfigurationError(f"Unexpected error during Elasticsearch setup: {str(e)}")

    @lambda_handler(
        logging_fn=logger,
        error_status=(
            (AccessDeniedError, 403),
            (ValidationError, 400),
            (ConfigurationError, 500),
            (SQSError, 500),
            (ElasticsearchFailedRequestError, 500),  # Add this error handling if not present
        ),
        require_user=True,
        sanitize=True,
    )
    def handler(event, context, user: User):
        logger.info(f"Event Received: {json.dumps(event)}")
        body = event_parser.extract_body(event)

        # Get credentials from the Transcribe Manager Cognito Group
        credentials = event_parser.extract_credentials(event)
        dynamodb_client = create_dynamodb_client_fn(credentials=credentials)
        dynamodb_mapper = DynamoDBMapper(dynamodb_client=dynamodb_client, logger=logger)
        sqs_client = create_sqs_client_fn(credentials=credentials)
        sqs_adapter = SQSAdapter(sqs_client=sqs_client, logger=logger)

        call_ids = body
        user_groups = get_user_groups(user.email)
        call_access_restriction_parameters = CallAccessRestrictionQueryParameter(
            user_groups
        )
        filters = {}
        call_access_restriction_query = call_access_restriction_parameters.create_query(
            filters
        )

        # Validate call IDs against Elasticsearch
        try:
            validate_calls_id_es(
                es_client, es_index, call_ids, call_access_restriction_query
            )
        except AccessDeniedError as e:
            logger.error(f"Access denied during Elasticsearch validation: {e}")
            raise AccessDeniedError("403 Forbidden: Access to Elasticsearch denied.")
        except ElasticsearchFailedRequestError as e:
            logger.error(f"Failed request to Elasticsearch during validation: {e}")
            raise
        except Exception as e:
            logger.error(f"Unexpected error during Elasticsearch validation: {e}")
            raise ValidationError(f"Unexpected error during call ID validation: {str(e)}")

        job_id = generate_job_id()

        # Update the DynamoDB table with the job_id and call_ids
        job_updater = OnRequestJobUpdater(
            dynamodb_mapper=dynamodb_mapper,
            dynamodb_status_table=transcribe_on_request_status_table,
            logger=logger,
        )
        job_updater(
            job_id=job_id,
            call_ids=call_ids,
            user_email=user.email,
            days_to_expire=days_to_expire,
        )

        # Publish the job to the SQS queue
        job_publisher = OnRequestJobPublisher(
            es_client=es_client, sqs_adapter=sqs_adapter, logger=logger
        )
        job_publisher(call_ids=call_ids, job_id=job_id, user_email=user.email)

        # Successful job creation of all requested call_ids
        return 201, call_ids

    return handler

